{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# data=pd.read_csv('C:\\\\Users\\\\josan\\\\Documents\\\\GitHub\\\\EDEM_MDA2324\\\\Alumnos\\\\ES\\\\Josan_Rodrigo_Cortes\\\\Dataproject3\\\\train.csv')\n",
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restecg</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.376712</td>\n",
       "      <td>0.791781</td>\n",
       "      <td>3.253425</td>\n",
       "      <td>0.604110</td>\n",
       "      <td>1.135616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.316814</td>\n",
       "      <td>0.406313</td>\n",
       "      <td>0.922301</td>\n",
       "      <td>0.803446</td>\n",
       "      <td>1.257937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp     restecg       label\n",
       "count  730.000000  730.000000  730.000000  730.000000  730.000000\n",
       "mean    53.376712    0.791781    3.253425    0.604110    1.135616\n",
       "std      9.316814    0.406313    0.922301    0.803446    1.257937\n",
       "min     28.000000    0.000000    1.000000    0.000000    0.000000\n",
       "25%     47.000000    1.000000    3.000000    0.000000    0.000000\n",
       "50%     54.000000    1.000000    4.000000    0.000000    1.000000\n",
       "75%     60.000000    1.000000    4.000000    1.000000    2.000000\n",
       "max     76.000000    1.000000    4.000000    2.000000    4.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quitamos los duplicados y comprobamos\n",
    "data = data.drop_duplicates(keep = False)\n",
    "data = data.drop_duplicates(keep = False)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reemplazar los valores '?' por NaN\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Eliminar todas las filas que contienen valores NaN\n",
    "data.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data >= 0].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en la columna 'age': [51 55 44 35 64 56 68 45 43 41 69 66 57 46 67 58 42 49 61 50 59 53 47 62\n",
      " 54 60 48 70 76 52 63 37 71 34 40 39 65 38 29]\n",
      "Valores únicos en la columna 'sex': [1 0]\n",
      "Valores únicos en la columna 'cp': [1 4 2 3]\n",
      "Valores únicos en la columna 'trestbps': [125 140 120 122 130 104 110 134 160 146 128 108 115 150 170 138 144 180\n",
      " 100 105 117 192 114 142 148 132 124 152 118 165 172 112 102 135 145 174\n",
      " 126 154 200 136  94 106 178 164 123]\n",
      "Valores únicos en la columna 'chol': [213. 217. 169. 192. 246. 256. 211. 208. 303. 177. 233. 172. 235. 409.\n",
      " 234. 278. 229. 249. 254. 180. 204. 141. 269. 260. 243. 295. 239. 326.\n",
      " 264. 226. 228. 257. 340. 193. 274. 263. 311. 126. 236. 222. 232. 283.\n",
      " 258. 212. 240. 214. 201. 164. 198. 230. 188. 197. 253. 318. 245. 313.\n",
      " 203. 157. 261. 341. 277. 209. 302. 322. 298. 149. 207. 289. 271. 242.\n",
      " 259. 199. 330. 200. 160. 215. 265. 131. 178. 182. 248. 250. 205. 305.\n",
      " 206. 244. 184. 216. 282. 342. 225. 185. 262. 267. 218. 294. 220. 276.\n",
      " 266. 308. 174. 321. 288. 268. 167. 168. 224. 307. 255. 293. 241. 299.\n",
      " 327. 284. 252. 231. 281. 309. 360. 210. 335. 196. 227. 273. 223. 286.\n",
      " 325. 100. 300. 195. 270. 176. 417. 564. 354. 221. 219. 186. 319. 315.\n",
      " 306.]\n",
      "Valores únicos en la columna 'fbs': [0. 1.]\n",
      "Valores únicos en la columna 'restecg': [2 0 1]\n",
      "Valores únicos en la columna 'thalach': [125 111 144 174  96 142 115 148 122 120 179 158 153 150 161 131 152 163\n",
      " 165 172 175 185 137 159 162 151 140 143 169 138 156 141  97 114 145 173\n",
      " 157 178 154 126 168 160 132 139 195 180 133 103 182 186 136 166 109 124\n",
      " 105 149 129 116 130 170 184 108 147 146 155 187  99 106 112 171 134 164\n",
      " 123 127 117 128 192 113 194  90  95 202 188 190 181]\n",
      "Valores únicos en la columna 'exang': [1 0]\n",
      "Valores únicos en la columna 'oldpeak': [1 5 2 0 3 6 4]\n",
      "Valores únicos en la columna 'slope': [1. 3. 2.]\n",
      "Valores únicos en la columna 'ca': [1. 0. 2. 3.]\n",
      "Valores únicos en la columna 'thal': [3. 7. 6.]\n",
      "Valores únicos en la columna 'label': [0 3 2 1 4]\n"
     ]
    }
   ],
   "source": [
    "for columna in data.columns:\n",
    "    valores_unicos = data[columna].unique()\n",
    "    print(f\"Valores únicos en la columna '{columna}': {valores_unicos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 246 entries, 0 to 731\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       246 non-null    int32  \n",
      " 1   sex       246 non-null    int32  \n",
      " 2   cp        246 non-null    int32  \n",
      " 3   trestbps  246 non-null    int32  \n",
      " 4   chol      246 non-null    float64\n",
      " 5   fbs       246 non-null    float64\n",
      " 6   restecg   246 non-null    int32  \n",
      " 7   thalach   246 non-null    int32  \n",
      " 8   exang     246 non-null    int32  \n",
      " 9   oldpeak   246 non-null    int32  \n",
      " 10  slope     246 non-null    float64\n",
      " 11  ca        246 non-null    float64\n",
      " 12  thal      246 non-null    float64\n",
      " 13  label     246 non-null    int32  \n",
      "dtypes: float64(5), int32(9)\n",
      "memory usage: 20.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:\\\\Users\\\\josan\\\\Documents\\\\GitHub\\\\EDEM_MDA2324\\\\Alumnos\\\\ES\\\\Josan_Rodrigo_Cortes\\\\Dataproject3\\\\test.csv', delimiter=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reemplazar los valores '?' por NaN\n",
    "test.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Eliminar todas las filas que contienen valores NaN\n",
    "test.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test >= 0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en la columna 'age': [51 54 60 62 48 47 39 50 52 59 77 64 57 46 63 44 35 43 65 61 67 55 71 42\n",
      " 58 45 70 74]\n",
      "Valores únicos en la columna 'sex': [1 0]\n",
      "Valores únicos en la columna 'cp': [3 4 2 1]\n",
      "Valores únicos en la columna 'trestbps': [110. 160. 125. 150. 130. 140. 118. 120. 129. 128. 145. 152. 101. 108.\n",
      " 105. 138. 115. 158. 112. 132. 155. 156. 135. 170.]\n",
      "Valores únicos en la columna 'chol': [175. 201. 258. 244. 275. 256. 239. 219. 196. 255. 221. 304. 212. 274.\n",
      " 197. 267. 407. 204. 183. 226. 268. 303. 248. 166. 206. 192. 237. 305.\n",
      " 290. 353. 289. 149. 187. 269. 209. 270. 234. 220. 247. 394. 315. 245.\n",
      " 211. 231. 273. 288.]\n",
      "Valores únicos en la columna 'fbs': [0 1]\n",
      "Valores únicos en la columna 'restecg': [0. 2.]\n",
      "Valores únicos en la columna 'thalach': [123. 163. 141. 154. 139. 149. 160. 118. 140. 158. 161. 164. 162. 132.\n",
      "  88. 156. 167. 177. 172. 182.  98. 181. 125. 148.  71. 153. 145. 144.\n",
      " 173. 111. 175. 152. 171. 157. 143. 121. 170. 146. 150. 159.]\n",
      "Valores únicos en la columna 'exang': [0. 1.]\n",
      "Valores únicos en la columna 'oldpeak': [0 2 1 4 3]\n",
      "Valores únicos en la columna 'slope': [1. 2. 3.]\n",
      "Valores únicos en la columna 'ca': [0. 1. 3. 2.]\n",
      "Valores únicos en la columna 'thal': [3. 7. 6.]\n"
     ]
    }
   ],
   "source": [
    "for column in test.columns:\n",
    "    valores_unicostest = test[column].unique()\n",
    "    print(f\"Valores únicos en la columna '{column}': {valores_unicostest}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52 entries, 4 to 182\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       52 non-null     int32  \n",
      " 1   sex       52 non-null     int32  \n",
      " 2   cp        52 non-null     int32  \n",
      " 3   trestbps  52 non-null     float64\n",
      " 4   chol      52 non-null     float64\n",
      " 5   fbs       52 non-null     int32  \n",
      " 6   restecg   52 non-null     float64\n",
      " 7   thalach   52 non-null     float64\n",
      " 8   exang     52 non-null     float64\n",
      " 9   oldpeak   52 non-null     int32  \n",
      " 10  slope     52 non-null     float64\n",
      " 11  ca        52 non-null     float64\n",
      " 12  thal      52 non-null     float64\n",
      "dtypes: float64(8), int32(5)\n",
      "memory usage: 4.7 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que tienes un DataFrame df y deseas dividirlo en conjuntos de entrenamiento y validación\n",
    "X = data.drop('label', axis=1)  # Features (variables independientes)\n",
    "y = data['label']  # Variable objetivo (variable dependiente)\n",
    "\n",
    "# Dividir el DataFrame en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# test_size=0.2 indica que el 20% de los datos se utilizarán para validación\n",
    "# random_state=42 establece una semilla aleatoria para reproducibilidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.5405405405405406\n",
      "Matriz de confusión:\n",
      "[[19  1  1  0  0]\n",
      " [ 5  0  0  0  0]\n",
      " [ 3  0  1  0  0]\n",
      " [ 4  1  1  0  0]\n",
      " [ 0  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Crear un clasificador k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Define el número de vecinos, puedes ajustarlo según sea necesario\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "y_pred = knn.predict(X_val)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precisionknn = accuracy_score(y_val, y_pred)\n",
    "print(\"Precisión del modelo:\", precisionknn)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusionknn = confusion_matrix(y_val, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusionknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.6486486486486487\n",
      "Matriz de confusión:\n",
      "[[21  0  0  0  0]\n",
      " [ 3  0  0  2  0]\n",
      " [ 1  1  2  0  0]\n",
      " [ 3  0  2  1  0]\n",
      " [ 1  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear un clasificador Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)  # Puedes ajustar el número de árboles (n_estimators)\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "y_pred_rf = random_forest.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precisionrf = accuracy_score(y_val, y_pred_rf)\n",
    "print(\"Precisión del modelo:\", precisionrf)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusionrf = confusion_matrix(y_val, y_pred_rf)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusionrf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.5675675675675675\n",
      "Matriz de confusión:\n",
      "[[18  3  0  0  0]\n",
      " [ 2  2  0  1  0]\n",
      " [ 0  2  0  1  1]\n",
      " [ 0  3  2  1  0]\n",
      " [ 0  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Crear un clasificador Naive Bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "y_pred_nb = naive_bayes.predict(X_val)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precisionnb = accuracy_score(y_val, y_pred_nb)\n",
    "print(\"Precisión del modelo:\", precisionnb)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusionnb = confusion_matrix(y_val, y_pred_nb)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusionnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.6486486486486487\n",
      "Matriz de confusión:\n",
      "[[18  2  1  0  0]\n",
      " [ 2  2  0  1  0]\n",
      " [ 0  1  3  0  0]\n",
      " [ 3  1  1  1  0]\n",
      " [ 0  1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Crear un clasificador Gradient Boosting\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)  \n",
    "# Puedes ajustar el número de árboles (n_estimators) y la tasa de aprendizaje (learning_rate)\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "y_pred_gb = gradient_boosting.predict(X_val)\n",
    "\n",
    "precisiongb = accuracy_score(y_val, y_pred_gb)\n",
    "print(\"Precisión del modelo:\", precisiongb)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusionnb = confusion_matrix(y_val, y_pred_gb)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusionnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.5675675675675675\n",
      "Matriz de confusión:\n",
      "[[18  2  1  0  0]\n",
      " [ 2  2  0  1  0]\n",
      " [ 0  3  0  1  0]\n",
      " [ 2  2  1  1  0]\n",
      " [ 0  1  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear un clasificador de regresión logística\n",
    "logistic_regression = LogisticRegression(random_state=42)  \n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "y_pred_lr = logistic_regression.predict(X_val)\n",
    "\n",
    "precisionrl = accuracy_score(y_val, y_pred_lr)\n",
    "print(\"Precisión del modelo:\", precisionrl)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusionrl = confusion_matrix(y_val, y_pred_lr)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusionrl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.5945945945945946\n",
      "Matriz de confusión:\n",
      "[[20  1  0  0  0]\n",
      " [ 3  1  0  1  0]\n",
      " [ 0  2  0  1  1]\n",
      " [ 2  1  2  1  0]\n",
      " [ 1  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear un clasificador SVM\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)  # Kernel lineal, puedes cambiarlo según sea necesario\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en los datos de validación\n",
    "y_pred_svm = svm_classifier.predict(X_val)\n",
    "\n",
    "precisionsvm = accuracy_score(y_val, y_pred_svm)\n",
    "print(\"Precisión del modelo:\", precisionsvm)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "matriz_confusionsvm = confusion_matrix(y_val, y_pred_svm)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(matriz_confusionsvm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
